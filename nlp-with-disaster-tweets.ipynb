{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.linear_model import LogisticRegression\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom gensim.models import Word2Vec\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-03T15:22:50.943303Z","iopub.execute_input":"2024-01-03T15:22:50.943742Z","iopub.status.idle":"2024-01-03T15:22:50.949917Z","shell.execute_reply.started":"2024-01-03T15:22:50.943701Z","shell.execute_reply":"2024-01-03T15:22:50.948938Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"load and display the content of two CSV files, which are typically used for building and evaluating machine learning models.","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\n\nprint(\"Train Data:\")\nprint(train_df.head())\nprint(\"\\nTest Data:\")\nprint(test_df.head())","metadata":{"execution":{"iopub.status.busy":"2024-01-03T15:22:50.951836Z","iopub.execute_input":"2024-01-03T15:22:50.952206Z","iopub.status.idle":"2024-01-03T15:22:51.020744Z","shell.execute_reply.started":"2024-01-03T15:22:50.952170Z","shell.execute_reply":"2024-01-03T15:22:51.018865Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Train Data:\n   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  \n\nTest Data:\n   id keyword location                                               text\n0   0     NaN      NaN                 Just happened a terrible car crash\n1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Show how many instances belong to each category in the 'target' column, making it a useful visualization for understanding the class distribution in a classification problem. ","metadata":{}},{"cell_type":"code","source":"sns.countplot(x='target', data=train_df)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-03T15:22:51.022578Z","iopub.execute_input":"2024-01-03T15:22:51.022974Z","iopub.status.idle":"2024-01-03T15:22:51.159332Z","shell.execute_reply.started":"2024-01-03T15:22:51.022919Z","shell.execute_reply":"2024-01-03T15:22:51.158171Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"Perform common text preprocessing steps, such as tokenization, lowercase conversion, and stopwords removal, to prepare the text data for further natural language processing or machine learning tasks.","metadata":{}},{"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\n\ndef preprocess_text(text):\n    words = word_tokenize(text)\n    words = [word.lower() for word in words if word.isalpha() and word.lower() not in stop_words]\n    return ' '.join(words)\n\ntrain_df['processed_text'] = train_df['text'].apply(preprocess_text)\ntest_df['processed_text'] = test_df['text'].apply(preprocess_text)","metadata":{"execution":{"iopub.status.busy":"2024-01-03T15:22:51.162777Z","iopub.execute_input":"2024-01-03T15:22:51.164055Z","iopub.status.idle":"2024-01-03T15:22:53.196172Z","shell.execute_reply.started":"2024-01-03T15:22:51.164014Z","shell.execute_reply":"2024-01-03T15:22:53.195165Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"Trains a Word2Vec model on the tokenized and preprocessed text data from the train_df DataFrame and saves the trained model for later use in word embedding-based natural language processing tasks.","metadata":{}},{"cell_type":"code","source":"from gensim.utils import simple_preprocess\n\ntokenized_text = [simple_preprocess(text) for text in train_df['processed_text']]\n\nword2vec_model = Word2Vec(sentences=tokenized_text, vector_size=100, window=5, min_count=1, workers=4)\n\nword2vec_model.save(\"word2vec_model\")","metadata":{"execution":{"iopub.status.busy":"2024-01-03T15:22:53.198403Z","iopub.execute_input":"2024-01-03T15:22:53.199003Z","iopub.status.idle":"2024-01-03T15:22:53.926513Z","shell.execute_reply.started":"2024-01-03T15:22:53.198862Z","shell.execute_reply":"2024-01-03T15:22:53.925389Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"Calculateing word embeddings for the processed text data in both the training and test datasets using a pre-trained Word2Vec model. These word embeddings can be used as numerical representations of the text data in machine learning models for various NLP tasks.","metadata":{}},{"cell_type":"code","source":"def get_word_embedding(text):\n    embedding = np.zeros(100)\n    count = 0\n    for word in text.split():\n        if word in word2vec_model.wv:\n            embedding += word2vec_model.wv[word]\n            count += 1\n    if count != 0:\n        embedding /= count\n    return embedding\n\ntrain_df['word_embedding'] = train_df['processed_text'].apply(get_word_embedding)\ntest_df['word_embedding'] = test_df['processed_text'].apply(get_word_embedding)","metadata":{"execution":{"iopub.status.busy":"2024-01-03T15:22:53.927639Z","iopub.execute_input":"2024-01-03T15:22:53.927940Z","iopub.status.idle":"2024-01-03T15:22:54.283510Z","shell.execute_reply.started":"2024-01-03T15:22:53.927912Z","shell.execute_reply":"2024-01-03T15:22:54.281935Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"Preparing the data by converting word embeddings and labels into NumPy arrays, splits the data into training and validation sets, and trains a logistic regression model on the training data to make predictions.","metadata":{}},{"cell_type":"code","source":"X = np.array(train_df['word_embedding'].to_list())\ny = np.array(train_df['target'])\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\nmodel = LogisticRegression(random_state=42)\nmodel.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-01-03T15:22:54.285407Z","iopub.execute_input":"2024-01-03T15:22:54.285839Z","iopub.status.idle":"2024-01-03T15:22:54.328137Z","shell.execute_reply.started":"2024-01-03T15:22:54.285800Z","shell.execute_reply":"2024-01-03T15:22:54.327144Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"LogisticRegression(random_state=42)","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Evaluating the logistic regression model's performance on the validation data, including accuracy and a detailed classification report, which helps assess how well the model is performing on the task of classifying the text data.","metadata":{}},{"cell_type":"code","source":"y_pred = model.predict(X_val)\n\naccuracy = accuracy_score(y_val, y_pred)\nclassification_rep = classification_report(y_val, y_pred)\n\nprint(f\"Model Accuracy: {accuracy:.2f}\")\nprint(\"Classification Report:\")\nprint(classification_rep)","metadata":{"execution":{"iopub.status.busy":"2024-01-03T15:22:54.329258Z","iopub.execute_input":"2024-01-03T15:22:54.329578Z","iopub.status.idle":"2024-01-03T15:22:54.353282Z","shell.execute_reply.started":"2024-01-03T15:22:54.329547Z","shell.execute_reply":"2024-01-03T15:22:54.352017Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Model Accuracy: 0.60\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.61      0.85      0.71       874\n           1       0.57      0.27      0.37       649\n\n    accuracy                           0.60      1523\n   macro avg       0.59      0.56      0.54      1523\nweighted avg       0.59      0.60      0.57      1523\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Building and training a sequential neural network model for text classification using Keras.","metadata":{}},{"cell_type":"code","source":"tokenizer = Tokenizer()\ntokenizer.fit_on_texts(train_df['processed_text'])\n\nsequences = tokenizer.texts_to_sequences(train_df['processed_text'])\nX_seq = pad_sequences(sequences, maxlen=50)  \n\nX_train_seq, X_val_seq, y_train_seq, y_val_seq = train_test_split(X_seq, y, test_size=0.2, random_state=42)\n\nmodel_seq = Sequential()\nmodel_seq.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_length=50))\nmodel_seq.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\nmodel_seq.add(Dense(1, activation='sigmoid'))\n\nmodel_seq.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nmodel_seq.fit(X_train_seq, y_train_seq, epochs=5, batch_size=32, validation_data=(X_val_seq, y_val_seq))","metadata":{"execution":{"iopub.status.busy":"2024-01-03T15:22:54.356138Z","iopub.execute_input":"2024-01-03T15:22:54.356834Z","iopub.status.idle":"2024-01-03T15:24:19.689968Z","shell.execute_reply.started":"2024-01-03T15:22:54.356797Z","shell.execute_reply":"2024-01-03T15:24:19.688526Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Epoch 1/5\n191/191 [==============================] - 15s 66ms/step - loss: 0.5381 - accuracy: 0.7218 - val_loss: 0.4453 - val_accuracy: 0.7984\nEpoch 2/5\n191/191 [==============================] - 12s 60ms/step - loss: 0.2907 - accuracy: 0.8831 - val_loss: 0.6230 - val_accuracy: 0.7249\nEpoch 3/5\n191/191 [==============================] - 12s 62ms/step - loss: 0.1735 - accuracy: 0.9379 - val_loss: 0.6007 - val_accuracy: 0.7623\nEpoch 4/5\n191/191 [==============================] - 12s 64ms/step - loss: 0.1138 - accuracy: 0.9619 - val_loss: 0.7364 - val_accuracy: 0.7426\nEpoch 5/5\n191/191 [==============================] - 12s 61ms/step - loss: 0.0846 - accuracy: 0.9716 - val_loss: 0.7362 - val_accuracy: 0.7518\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7f9265b168c0>"},"metadata":{}}]},{"cell_type":"markdown","source":"Evaluating the performance of the previously trained sequential neural network model on a validation set and test set.","metadata":{}},{"cell_type":"code","source":"sequences_test = tokenizer.texts_to_sequences(test_df['processed_text'])\nX_test_seq = pad_sequences(sequences_test, maxlen=50)\n\nloss, accuracy = model_seq.evaluate(X_val_seq, y_val_seq)\nprint(f\"Sequential Model Accuracy on Validation Set: {accuracy:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-03T15:24:19.691733Z","iopub.execute_input":"2024-01-03T15:24:19.692390Z","iopub.status.idle":"2024-01-03T15:24:20.365909Z","shell.execute_reply.started":"2024-01-03T15:24:19.692355Z","shell.execute_reply":"2024-01-03T15:24:20.364819Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"48/48 [==============================] - 1s 11ms/step - loss: 0.7362 - accuracy: 0.7518\nSequential Model Accuracy on Validation Set: 0.75\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Transforming the model's probability predictions into binary predictions (0 or 1) based on a threshold of 0.5, making it suitable for binary classification tasks.","metadata":{}},{"cell_type":"code","source":"test_predictions_seq = (model_seq.predict(X_test_seq) > 0.5).astype(\"int32\")","metadata":{"execution":{"iopub.status.busy":"2024-01-03T15:24:20.370073Z","iopub.execute_input":"2024-01-03T15:24:20.370478Z","iopub.status.idle":"2024-01-03T15:24:21.879756Z","shell.execute_reply.started":"2024-01-03T15:24:20.370447Z","shell.execute_reply":"2024-01-03T15:24:21.878781Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"102/102 [==============================] - 1s 12ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"submission_df_seq = pd.DataFrame({'id': test_df['id'], 'target': test_predictions_seq.flatten()})\n\nsubmission_df_seq.to_csv(\"submission_seq.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-03T15:24:21.880931Z","iopub.execute_input":"2024-01-03T15:24:21.881308Z","iopub.status.idle":"2024-01-03T15:24:21.895156Z","shell.execute_reply.started":"2024-01-03T15:24:21.881276Z","shell.execute_reply":"2024-01-03T15:24:21.893785Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"The overall purpose of this code is to demonstrate the process of preparing text data, training machine learning models (logistic regression) and deep learning models (sequential neural network), and evaluating their performance on a binary classification task. It also covers text preprocessing and word embeddings using Word2Vec, which are essential steps in many NLP applications.","metadata":{}}]}